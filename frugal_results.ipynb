{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/cse/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/cse/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/cse/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "meteor = evaluate.load('meteor')\n",
    "bertscore = evaluate.load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Negative', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frugal_icl_results(attribution_method, model_name, dataset_name, threshold):\n",
    "    with open(f'responses/{attribution_method}/{model_name}_{dataset_name}_test_{threshold}.json') as data_file:\n",
    "        d = json.load(data_file)\n",
    "    test_data = pd.DataFrame.from_dict(d)\n",
    "    print(classification_report(test_data['label'].tolist(), test_data['pred'].tolist(), target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9506    0.9315    0.9409       496\n",
      "    Positive     0.9339    0.9524    0.9430       504\n",
      "\n",
      "    accuracy                         0.9420      1000\n",
      "   macro avg     0.9422    0.9419    0.9420      1000\n",
      "weighted avg     0.9422    0.9420    0.9420      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_8b', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9601    0.9214    0.9403       496\n",
      "    Positive     0.9256    0.9623    0.9436       504\n",
      "\n",
      "    accuracy                         0.9420      1000\n",
      "   macro avg     0.9428    0.9418    0.9420      1000\n",
      "weighted avg     0.9427    0.9420    0.9420      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_8b', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9542    0.8831    0.9173       496\n",
      "    Positive     0.8928    0.9583    0.9244       504\n",
      "\n",
      "    accuracy                         0.9210      1000\n",
      "   macro avg     0.9235    0.9207    0.9208      1000\n",
      "weighted avg     0.9233    0.9210    0.9209      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_8b', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9576    0.9113    0.9339       496\n",
      "    Positive     0.9167    0.9603    0.9380       504\n",
      "\n",
      "    accuracy                         0.9360      1000\n",
      "   macro avg     0.9371    0.9358    0.9359      1000\n",
      "weighted avg     0.9370    0.9360    0.9360      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_8b', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8822    0.9214    0.9014       496\n",
      "    Positive     0.9191    0.8790    0.8986       504\n",
      "\n",
      "    accuracy                         0.9000      1000\n",
      "   macro avg     0.9007    0.9002    0.9000      1000\n",
      "weighted avg     0.9008    0.9000    0.9000      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_8b', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8333    0.9173    0.8733       496\n",
      "    Positive     0.9097    0.8194    0.8622       504\n",
      "\n",
      "    accuracy                         0.8680      1000\n",
      "   macro avg     0.8715    0.8684    0.8678      1000\n",
      "weighted avg     0.8718    0.8680    0.8677      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_8b', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9606    0.9335    0.9468       496\n",
      "    Positive     0.9363    0.9623    0.9491       504\n",
      "\n",
      "    accuracy                         0.9480      1000\n",
      "   macro avg     0.9484    0.9479    0.9480      1000\n",
      "weighted avg     0.9483    0.9480    0.9480      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_70b', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9602    0.9234    0.9414       496\n",
      "    Positive     0.9273    0.9623    0.9445       504\n",
      "\n",
      "    accuracy                         0.9430      1000\n",
      "   macro avg     0.9438    0.9428    0.9430      1000\n",
      "weighted avg     0.9436    0.9430    0.9430      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_70b', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9559    0.9173    0.9362       496\n",
      "    Positive     0.9218    0.9583    0.9397       504\n",
      "\n",
      "    accuracy                         0.9380      1000\n",
      "   macro avg     0.9388    0.9378    0.9380      1000\n",
      "weighted avg     0.9387    0.9380    0.9380      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'llama3_70b', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9645    0.9315    0.9477       496\n",
      "    Positive     0.9347    0.9663    0.9502       504\n",
      "\n",
      "    accuracy                         0.9490      1000\n",
      "   macro avg     0.9496    0.9489    0.9490      1000\n",
      "weighted avg     0.9495    0.9490    0.9490      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_70b', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8389    0.9657    0.8978       496\n",
      "    Positive     0.9604    0.8175    0.8832       504\n",
      "\n",
      "    accuracy                         0.8910      1000\n",
      "   macro avg     0.8996    0.8916    0.8905      1000\n",
      "weighted avg     0.9001    0.8910    0.8904      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_70b', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7680    0.9677    0.8564       496\n",
      "    Positive     0.9573    0.7123    0.8168       504\n",
      "\n",
      "    accuracy                         0.8390      1000\n",
      "   macro avg     0.8627    0.8400    0.8366      1000\n",
      "weighted avg     0.8634    0.8390    0.8364      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'llama3_70b', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9249    0.9677    0.9458       496\n",
      "    Positive     0.9667    0.9226    0.9442       504\n",
      "\n",
      "    accuracy                         0.9450      1000\n",
      "   macro avg     0.9458    0.9452    0.9450      1000\n",
      "weighted avg     0.9460    0.9450    0.9450      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'gpt3.5', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8905    0.9677    0.9275       496\n",
      "    Positive     0.9653    0.8829    0.9223       504\n",
      "\n",
      "    accuracy                         0.9250      1000\n",
      "   macro avg     0.9279    0.9253    0.9249      1000\n",
      "weighted avg     0.9282    0.9250    0.9249      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'gpt3.5', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8805    0.9657    0.9212       496\n",
      "    Positive     0.9627    0.8710    0.9146       504\n",
      "\n",
      "    accuracy                         0.9180      1000\n",
      "   macro avg     0.9216    0.9184    0.9179      1000\n",
      "weighted avg     0.9219    0.9180    0.9178      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('globenc', 'gpt3.5', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9179    0.9698    0.9431       496\n",
      "    Positive     0.9685    0.9147    0.9408       504\n",
      "\n",
      "    accuracy                         0.9420      1000\n",
      "   macro avg     0.9432    0.9422    0.9420      1000\n",
      "weighted avg     0.9434    0.9420    0.9420      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'gpt3.5', 'imdb', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.6444    0.9899    0.7806       496\n",
      "    Positive     0.9790    0.4623    0.6280       504\n",
      "\n",
      "    accuracy                         0.7240      1000\n",
      "   macro avg     0.8117    0.7261    0.7043      1000\n",
      "weighted avg     0.8130    0.7240    0.7037      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'gpt3.5', 'imdb', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.5816    0.9919    0.7332       496\n",
      "    Positive     0.9740    0.2976    0.4559       504\n",
      "\n",
      "    accuracy                         0.6420      1000\n",
      "   macro avg     0.7778    0.6448    0.5946      1000\n",
      "weighted avg     0.7794    0.6420    0.5935      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_icl_results('decompx', 'gpt3.5', 'imdb', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frugal_summarization_results(attribution_method, model_name, dataset_name, threshold):\n",
    "    print(f'{attribution_method} {model_name} {dataset_name} {threshold}')\n",
    "    with open(f'responses/{attribution_method}/{model_name}_{dataset_name}_test_{threshold}.json') as data_file:\n",
    "        d = json.load(data_file)\n",
    "    predictions = [item['response'] for item in d]\n",
    "    references = [item['prediction'][0]['text'] for item in d]\n",
    "    results = bleu.compute(predictions=predictions, references=references)\n",
    "    print(f'BLEU: {results[\"bleu\"]}')\n",
    "    results = rouge.compute(predictions=predictions, references=references) \n",
    "    print(f'ROUGE: {results}')\n",
    "    results = meteor.compute(predictions=predictions, references=references)\n",
    "    print(f'METEOR: {results}')\n",
    "    results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "    print(f'BERTScore: {np.mean(results[\"f1\"])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globenc llama3_70b argilla_news 80\n",
      "BLEU: 0.017948128546239235\n",
      "ROUGE: {'rouge1': 0.23455718761726824, 'rouge2': 0.07101901318824658, 'rougeL': 0.19493332030536611, 'rougeLsum': 0.19487934130012355}\n",
      "METEOR: {'meteor': 0.33059439984150774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: 0.8745496668219567\n",
      "\n",
      "globenc llama3_70b argilla_news 60\n",
      "BLEU: 0.0171869111462639\n",
      "ROUGE: {'rouge1': 0.23124904182118375, 'rouge2': 0.06825439443447955, 'rougeL': 0.19188161812476232, 'rougeLsum': 0.19168804361778413}\n",
      "METEOR: {'meteor': 0.3285932134564875}\n",
      "BERTScore: 0.8740010181665421\n",
      "\n",
      "globenc llama3_70b argilla_news 50\n",
      "BLEU: 0.016155157665230038\n",
      "ROUGE: {'rouge1': 0.2276209376192755, 'rouge2': 0.06522830267478333, 'rougeL': 0.18866631946753093, 'rougeLsum': 0.18851731435092103}\n",
      "METEOR: {'meteor': 0.3162967357635006}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: 0.872528975367546\n",
      "\n",
      "globenc gpt3.5 argilla_news 80\n",
      "BLEU: 0.01699929231021046\n",
      "ROUGE: {'rouge1': 0.17600392889659086, 'rouge2': 0.05647358563108383, 'rougeL': 0.14580242725061743, 'rougeLsum': 0.14567893392870018}\n",
      "METEOR: {'meteor': 0.28478751198560026}\n",
      "BERTScore: 0.8742550149559974\n",
      "\n",
      "globenc gpt3.5 argilla_news 60\n",
      "BLEU: 0.014755862361676258\n",
      "ROUGE: {'rouge1': 0.17169515590478923, 'rouge2': 0.05182581739473373, 'rougeL': 0.141278150365646, 'rougeLsum': 0.14121414382562048}\n",
      "METEOR: {'meteor': 0.27779224766838884}\n",
      "BERTScore: 0.8735281760692597\n",
      "\n",
      "globenc gpt3.5 argilla_news 50\n",
      "BLEU: 0.013739119923559216\n",
      "ROUGE: {'rouge1': 0.17011234203003361, 'rouge2': 0.048571691586557005, 'rougeL': 0.1400878415276276, 'rougeLsum': 0.14006509851062038}\n",
      "METEOR: {'meteor': 0.2679574566874844}\n",
      "BERTScore: 0.8727953988313675\n",
      "\n",
      "globenc llama3_8b argilla_news 80\n",
      "BLEU: 0.017142710198672913\n",
      "ROUGE: {'rouge1': 0.22624924739237762, 'rouge2': 0.06854011788160275, 'rougeL': 0.18867764511705137, 'rougeLsum': 0.18852896941888508}\n",
      "METEOR: {'meteor': 0.32967423971079013}\n",
      "BERTScore: 0.8711479362845421\n",
      "\n",
      "globenc llama3_8b argilla_news 60\n",
      "BLEU: 0.015491487040759819\n",
      "ROUGE: {'rouge1': 0.2198594533967009, 'rouge2': 0.06366312606093225, 'rougeL': 0.1812268703915768, 'rougeLsum': 0.180961043625459}\n",
      "METEOR: {'meteor': 0.3189375763283737}\n",
      "BERTScore: 0.8698343042731285\n",
      "\n",
      "globenc llama3_8b argilla_news 50\n",
      "BLEU: 0.013161140620249413\n",
      "ROUGE: {'rouge1': 0.21308437943438918, 'rouge2': 0.057042031107423424, 'rougeL': 0.17526171240412863, 'rougeLsum': 0.17530603546105752}\n",
      "METEOR: {'meteor': 0.3032773810524129}\n",
      "BERTScore: 0.8681045886874199\n",
      "\n",
      "decompx llama3_70b argilla_news 80\n",
      "BLEU: 0.01687178584469215\n",
      "ROUGE: {'rouge1': 0.2257700864775328, 'rouge2': 0.06530949836408252, 'rougeL': 0.18651499774545813, 'rougeLsum': 0.18641987358232773}\n",
      "METEOR: {'meteor': 0.316339272967925}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: 0.8702439113855361\n",
      "\n",
      "decompx llama3_70b argilla_news 60\n",
      "BLEU: 0.01455585402283058\n",
      "ROUGE: {'rouge1': 0.2148065379049417, 'rouge2': 0.056859767299841234, 'rougeL': 0.17618901929304512, 'rougeLsum': 0.17587286324499643}\n",
      "METEOR: {'meteor': 0.2924066542484425}\n",
      "BERTScore: 0.8684349508285523\n",
      "\n",
      "decompx llama3_70b argilla_news 50\n",
      "BLEU: 0.013881187981165215\n",
      "ROUGE: {'rouge1': 0.20879373128317472, 'rouge2': 0.05402196874458078, 'rougeL': 0.1708754665706862, 'rougeLsum': 0.17063575084441365}\n",
      "METEOR: {'meteor': 0.2813652650731808}\n",
      "BERTScore: 0.8664922308921814\n",
      "\n",
      "decompx gpt3.5 argilla_news 80\n",
      "BLEU: 0.03586259396527457\n",
      "ROUGE: {'rouge1': 0.2678615804860499, 'rouge2': 0.08429438862165703, 'rougeL': 0.2245637765061497, 'rougeLsum': 0.22445999951705561}\n",
      "METEOR: {'meteor': 0.3373148464613475}\n",
      "BERTScore: 0.8880208370685577\n",
      "\n",
      "decompx gpt3.5 argilla_news 60\n",
      "BLEU: 0.030630541329386952\n",
      "ROUGE: {'rouge1': 0.2532748872299238, 'rouge2': 0.072817210558634, 'rougeL': 0.2095540991786817, 'rougeLsum': 0.20941408489609215}\n",
      "METEOR: {'meteor': 0.31061066239931273}\n",
      "BERTScore: 0.8846336079239845\n",
      "\n",
      "decompx gpt3.5 argilla_news 50\n",
      "BLEU: 0.02708403525527349\n",
      "ROUGE: {'rouge1': 0.24103526961266125, 'rouge2': 0.06496789898196274, 'rougeL': 0.19959102181972527, 'rougeLsum': 0.1993678522431836}\n",
      "METEOR: {'meteor': 0.29077640087345336}\n",
      "BERTScore: 0.8822109928131103\n",
      "\n",
      "decompx llama3_8b argilla_news 80\n",
      "BLEU: 0.014737425852053123\n",
      "ROUGE: {'rouge1': 0.21763848936756, 'rouge2': 0.061207107639186645, 'rougeL': 0.17920799492318956, 'rougeLsum': 0.17910473187518633}\n",
      "METEOR: {'meteor': 0.31065465663279396}\n",
      "BERTScore: 0.8692385779619217\n",
      "\n",
      "decompx llama3_8b argilla_news 60\n",
      "BLEU: 0.013872610146838459\n",
      "ROUGE: {'rouge1': 0.20550085287458836, 'rouge2': 0.05465023478205926, 'rougeL': 0.1688306709832542, 'rougeLsum': 0.16849376045103168}\n",
      "METEOR: {'meteor': 0.2858231213400322}\n",
      "BERTScore: 0.8661661919355392\n",
      "\n",
      "decompx llama3_8b argilla_news 50\n",
      "BLEU: 0.011889956793943326\n",
      "ROUGE: {'rouge1': 0.1976594671180608, 'rouge2': 0.04839089228863221, 'rougeL': 0.16084925392214683, 'rougeLsum': 0.1606899423455363}\n",
      "METEOR: {'meteor': 0.27015382711256963}\n",
      "BERTScore: 0.8642402324080467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_frugal_summarization_results('globenc', 'llama3_70b', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('globenc', 'llama3_70b', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('globenc', 'llama3_70b', 'argilla_news', 50)\n",
    "get_frugal_summarization_results('globenc', 'gpt3.5', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('globenc', 'gpt3.5', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('globenc', 'gpt3.5', 'argilla_news', 50)\n",
    "get_frugal_summarization_results('globenc', 'llama3_8b', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('globenc', 'llama3_8b', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('globenc', 'llama3_8b', 'argilla_news', 50)\n",
    "get_frugal_summarization_results('decompx', 'llama3_70b', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('decompx', 'llama3_70b', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('decompx', 'llama3_70b', 'argilla_news', 50)\n",
    "get_frugal_summarization_results('decompx', 'gpt3.5', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('decompx', 'gpt3.5', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('decompx', 'gpt3.5', 'argilla_news', 50)\n",
    "get_frugal_summarization_results('decompx', 'llama3_8b', 'argilla_news', 80)\n",
    "get_frugal_summarization_results('decompx', 'llama3_8b', 'argilla_news', 60)\n",
    "get_frugal_summarization_results('decompx', 'llama3_8b', 'argilla_news', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rifat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
